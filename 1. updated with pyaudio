# intelligent_suite.py

# =========================
# Imports & Config
# =========================
import streamlit as st
st.set_page_config(page_title="Intelligent Data Suite", layout="wide", initial_sidebar_state="expanded")

import pandas as pd
import numpy as np
from sklearn.impute import KNNImputer
from sklearn.linear_model import LinearRegression
import plotly.express as px
import plotly.graph_objects as go
import pickle
import json
from datetime import datetime

# Optional voice features
voice_enabled = False
try:
    import pyttsx3
    import speech_recognition as sr
    voice_enabled = True
except:
    st.warning("Voice features disabled. Install pyttsx3 and SpeechRecognition for voice support.")

# =========================
# Title
# =========================
st.title("Intelligent Data Suite")
st.markdown("---")

# =========================
# Sidebar Navigation
# =========================
step = st.sidebar.radio("Navigation", [
    "Upload & Assessment",
    "Cleaning & Imputation",
    "Filtering & Selection",
    "Visualization",
    "AI Queries",
    "Prediction",
    "Save/Load Session",
    "Audit Trail"
])

# =========================
# Session State Initialization
# =========================
if 'df' not in st.session_state:
    st.session_state.df = None
if 'df_filtered' not in st.session_state:
    st.session_state.df_filtered = None
if 'logs' not in st.session_state:
    st.session_state.logs = []

# =========================
# Helper Functions
# =========================
def log_action(action, details=""):
    entry = {"timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
             "action": action, "details": details}
    st.session_state.logs.append(entry)
    with open("audit_log.json","a") as f:
        f.write(json.dumps(entry)+"\n")

def calculate_quality(df):
    total_cols = df.shape[1]
    total_rows = df.shape[0]
    missing_pct = df.isnull().sum().sum() / (total_rows*total_cols) * 100
    duplicate_pct = df.duplicated().sum() / total_rows * 100
    numeric_cols = df.select_dtypes(include=np.number)
    if not numeric_cols.empty:
        z = np.abs((numeric_cols - numeric_cols.mean()) / numeric_cols.std(ddof=0))
        outlier_pct = (z > 3).sum().sum() / np.prod(numeric_cols.shape) * 100
    else:
        outlier_pct = 0
    total_quality = 100 - (missing_pct*0.5 + duplicate_pct*0.2 + outlier_pct*0.3)
    return round(total_quality,2), round(missing_pct,2), round(duplicate_pct,2), round(outlier_pct,2)

def speak_text(text):
    if voice_enabled:
        engine = pyttsx3.init()
        engine.say(text)
        engine.runAndWait()

def listen_speech():
    if voice_enabled:
        r = sr.Recognizer()
        with sr.Microphone() as source:
            st.info("Listening...")
            audio = r.listen(source, phrase_time_limit=5)
        try:
            text = r.recognize_google(audio)
            return text
        except:
            return ""
    return ""

# =========================
# Upload & Assessment
# =========================
if step == "Upload & Assessment":
    st.header("Upload Dataset & Assess Quality")
    uploaded_file = st.file_uploader("Upload CSV/Excel", type=['csv','xlsx'])
    if uploaded_file:
        if uploaded_file.name.endswith('.csv'):
            df = pd.read_csv(uploaded_file)
        else:
            df = pd.read_excel(uploaded_file)
        st.session_state.df = df.copy()
        st.session_state.df_filtered = df.copy()
        st.subheader("Dataset Preview")
        st.dataframe(df.head())

        score, miss, dup, outl = calculate_quality(df)
        st.subheader("Data Quality Overview")
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("Overall Quality", f"{score}%")
        col2.metric("Missing %", f"{miss}%")
        col3.metric("Duplicates %", f"{dup}%")
        col4.metric("Outliers %", f"{outl}%")
        fig = go.Figure(go.Indicator(
            mode="gauge+number",
            value=score,
            title={'text': "Data Quality Score"},
            gauge={'axis': {'range':[0,100]},
                   'bar': {'color':'green'},
                   'steps':[{'range':[0,50],'color':'red'},
                            {'range':[50,75],'color':'yellow'},
                            {'range':[75,100],'color':'green'}]}))
        st.plotly_chart(fig, use_container_width=True)
        log_action("upload_dataset", uploaded_file.name)

# =========================
# Cleaning & Imputation
# =========================
elif step == "Cleaning & Imputation":
    st.header("Data Cleaning & Imputation")
    if st.session_state.df is not None:
        df = st.session_state.df.copy()
        score, miss, dup, outl = calculate_quality(df)
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("Overall Quality", f"{score}%")
        col2.metric("Missing %", f"{miss}%")
        col3.metric("Duplicates %", f"{dup}%")
        col4.metric("Outliers %", f"{outl}%")

        if st.checkbox("Perform Imputation"):
            method = st.selectbox("Imputation Method", ["Mean", "Median", "KNN"])
            if st.button("Apply Imputation"):
                numeric_cols = df.select_dtypes(include=np.number).columns
                cat_cols = df.select_dtypes(include='object').columns

                if method == "Mean":
                    df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())
                elif method == "Median":
                    df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())
                else:
                    imputer = KNNImputer(n_neighbors=5)
                    df[numeric_cols] = imputer.fit_transform(df[numeric_cols])

                for col in cat_cols:
                    df[col] = df[col].fillna(df[col].mode()[0])

                st.session_state.df = df.copy()
                st.session_state.df_filtered = df.copy()
                st.success("Imputation Applied Successfully")
                log_action("imputation", method)

# =========================
# Filtering & Selection
# =========================
elif step == "Filtering & Selection":
    st.header("Filter Data for Analysis")
    if st.session_state.df is not None:
        df = st.session_state.df.copy()
        filter_col = st.selectbox("Filter Column (Optional)", [None]+list(df.columns))
        if filter_col:
            unique_values = df[filter_col].dropna().unique()
            selected_values = st.multiselect(f"Select values from {filter_col}", unique_values)
            if selected_values:
                df_filtered = df[df[filter_col].isin(selected_values)]
            else:
                df_filtered = df.copy()
        else:
            df_filtered = df.copy()
        st.session_state.df_filtered = df_filtered
        st.subheader("Filtered Dataset Preview")
        st.dataframe(df_filtered.head())
        log_action("filter_data", f"{filter_col}: {selected_values if filter_col else 'All'}")

# =========================
# Visualization
# =========================
elif step == "Visualization":
    st.header("Interactive Visualization")
    if st.session_state.df_filtered is not None:
        df_filtered = st.session_state.df_filtered
        numeric_cols = df_filtered.select_dtypes(include=np.number).columns.tolist()
        cat_cols = df_filtered.select_dtypes(include='object').columns.tolist()

        if numeric_cols:
            x_axis = st.selectbox("X-axis", df_filtered.columns)
            y_axis = st.selectbox("Y-axis (numeric)", numeric_cols)
            chart_type = st.selectbox("Chart Type", ["Bar","Line","Scatter","Box","Histogram"])
            if chart_type=="Bar": fig=px.bar(df_filtered, x=x_axis, y=y_axis)
            elif chart_type=="Line": fig=px.line(df_filtered, x=x_axis, y=y_axis)
            elif chart_type=="Scatter": fig=px.scatter(df_filtered, x=x_axis, y=y_axis)
            elif chart_type=="Box": fig=px.box(df_filtered, x=x_axis, y=y_axis)
            else: fig=px.histogram(df_filtered, x=y_axis)
            st.plotly_chart(fig,use_container_width=True)

        if cat_cols:
            cat_col = st.selectbox("Categorical Column", cat_cols)
            fig_cat = px.pie(df_filtered, names=cat_col, title=f"Distribution of {cat_col}")
            st.plotly_chart(fig_cat,use_container_width=True)

# =========================
# AI Queries
# =========================
elif step == "AI Queries":
    st.header("Ask Questions About Your Dataset")
    if st.session_state.df_filtered is not None:
        df_filtered = st.session_state.df_filtered
        input_type = st.radio("Input Type", ["Text", "Voice"])
        user_query = ""
        if input_type=="Text":
            user_query = st.text_input("Type your question")
        else:
            if st.button("Record Question"):
                user_query = listen_speech()
                st.write("You said:", user_query)

        if user_query:
            q = user_query.lower()
            response = None
            # Numeric queries
            if "mean" in q:
                response = df_filtered.mean(numeric_only=True)
            elif "sum" in q:
                response = df_filtered.sum(numeric_only=True)
            elif "describe" in q:
                response = df_filtered.describe(include='all')
            elif "insight" in q or "summary" in q:
                numeric_summary = df_filtered.describe().T
                cat_summary = df_filtered.select_dtypes('object').describe().T
                response = {"numeric_summary": numeric_summary.to_dict(), "categorical_summary": cat_summary.to_dict()}
            else:
                for col in df_filtered.columns:
                    if col.lower() in q:
                        if df_filtered[col].dtype=='object':
                            response = df_filtered[col].unique()
                        else:
                            response = df_filtered[col].tolist()
                        break
            if response is None:
                response="Query not recognized. Try: mean, sum, describe, insight, or column name"
            st.write(response)
            speak_text(str(response))
            log_action("AI_query", user_query)
    else:
        st.warning("Filter or upload dataset first!")

# =========================
# Prediction
# =========================
elif step == "Prediction":
    st.header("Prediction")
    if st.session_state.df_filtered is not None:
        df_filtered = st.session_state.df_filtered
        numeric_cols = df_filtered.select_dtypes(include=np.number).columns.tolist()
        if len(numeric_cols)>=2:
            feature = st.selectbox("Feature Column", numeric_cols)
            target = st.selectbox("Target Column", [c for c in numeric_cols if c!=feature])
            if st.button("Run Prediction"):
                X = df_filtered[[feature]]
                y = df_filtered[target]
                model = LinearRegression()
                model.fit(X,y)
                df_filtered['Prediction']=model.predict(X)
                st.session_state.df_filtered = df_filtered
                fig_pred = px.scatter(df_filtered, x=feature, y=[target,'Prediction'], title=f"{target} vs Prediction")
                st.plotly_chart(fig_pred,use_container_width=True)
                st.success("Prediction Completed")
                log_action("prediction", f"{feature} -> {target}")
        else:
            st.write("Need at least 2 numeric columns for prediction")
    else:
        st.warning("Filter or upload dataset first!")

# =========================
# Save/Load Session
# =========================
elif step == "Save/Load Session":
    st.header("Save/Load Analysis Session")
    if st.session_state.df_filtered is not None:
        col1,col2 = st.columns(2)
        with col1:
            if st.button("Save Session"):
                with open("saved_session.pkl","wb") as f:
                    pickle.dump(st.session_state.df_filtered,f)
                st.success("Session Saved")
                log_action("save_session")
        with col2:
            if st.button("Load Session"):
                try:
                    with open("saved_session.pkl","rb") as f:
                        df_loaded = pickle.load(f)
                    st.session_state.df_filtered = df_loaded
                    st.dataframe(df_loaded.head())
                    st.success("Session Loaded")
                    log_action("load_session")
                except:
                    st.error("No saved session found")
    else:
        st.warning("Filter or upload dataset first!")

# =========================
# Audit Trail
# =========================
elif step == "Audit Trail":
    st.header("Audit Trail")
    if st.session_state.logs:
        for entry in st.session_state.logs[::-1]:
            st.markdown(f"[{entry['timestamp']}] **{entry['action']}**: {entry['details']}")
    else:
        st.write("No actions logged yet.")
